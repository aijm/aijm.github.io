<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>羽觞的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-12-05T19:30:37.733Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>羽觞</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>error C2589: (: ::右边的非法标记</title>
    <link href="http://yoursite.com/2018/11/25/error-C2589-%E5%8F%B3%E8%BE%B9%E7%9A%84%E9%9D%9E%E6%B3%95%E6%A0%87%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/11/25/error-C2589-右边的非法标记/</id>
    <published>2018-11-25T06:04:36.000Z</published>
    <updated>2018-12-05T19:30:37.733Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>原文：<a href="https://blog.csdn.net/zhuangshn/article/details/5537499" target="_blank" rel="noopener">https://blog.csdn.net/zhuangshn/article/details/5537499</a> </p></blockquote><h2 id="error-C2589-“-”-“-”右边的非法标记"><a href="#error-C2589-“-”-“-”右边的非法标记" class="headerlink" title="error C2589: “(”: “::”右边的非法标记"></a>error C2589: “(”: “::”右边的非法标记</h2><ol><li><p>错误输出<br> error C2589: “(”: “::”右边的非法标记</p><p> error C2059: 语法错误 : “::”</p></li><li><p>错误代码举例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_choices = std::max(1, std::min(26, num_choices));</span><br></pre></td></tr></table></figure></li><li><p>函数模板max   </p><p>注：模板就是实现代码重用机制的一种工具，它可以实现类型参数化，即把类型定义为参数， 从而实现了真正的代码可重用性。模版可以分为两类，一个是函数模版，另外一个是类模版。</p></li><li><p>错误原因</p><p>函数模板max与Visual C++中的全局的宏max冲突。 </p></li><li><p>解决办法</p><p> 第一种办法：设置项目属性，在预定义处理器中添加定义<code>NOMINMAX</code>来禁止使用Vsual C++的min/max宏定义。</p><p> 项目属性   ——&gt; C/C++ ——&gt; 预处理器 ——&gt; 预处理器定义 (此处添加预定义编译开关   NOMINMAX）</p><p> 第二种办法： 加上括号，与Vsual C++的min/max宏定义区分开</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_choices = (std::max)(1, std::min(26, num_choices));</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;原文：&lt;a href=&quot;https://blog.csdn.net/zhuangshn/article/details/5537499&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/zh
      
    
    </summary>
    
      <category term="error" scheme="http://yoursite.com/categories/error/"/>
    
    
      <category term="C++" scheme="http://yoursite.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>cmake find_path(),windows带空格的路径</title>
    <link href="http://yoursite.com/2018/11/25/cmake-find-path-windows%E5%B8%A6%E7%A9%BA%E6%A0%BC%E7%9A%84%E8%B7%AF%E5%BE%84/"/>
    <id>http://yoursite.com/2018/11/25/cmake-find-path-windows带空格的路径/</id>
    <published>2018-11-25T02:54:21.000Z</published>
    <updated>2018-12-05T19:35:16.277Z</updated>
    
    <content type="html"><![CDATA[<p>cmake中的windows 路径如果有空格，比如<code>D:/Program Files/libigl</code>, 需要改成<code>D:/Program\ Files/libigl</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">find_path(LIBIGL_INCLUDE_DIR igl/readOBJ.h</span><br><span class="line">    HINTS</span><br><span class="line">        ENV LIBIGL</span><br><span class="line">        ENV LIBIGLROOT</span><br><span class="line">        ENV LIBIGL_ROOT</span><br><span class="line">        ENV LIBIGL_DIR</span><br><span class="line">    PATHS</span><br><span class="line">        $&#123;CMAKE_SOURCE_DIR&#125;/../..</span><br><span class="line">        $&#123;CMAKE_SOURCE_DIR&#125;/..</span><br><span class="line">        $&#123;CMAKE_SOURCE_DIR&#125;</span><br><span class="line">        $&#123;CMAKE_SOURCE_DIR&#125;/libigl</span><br><span class="line">        $&#123;CMAKE_SOURCE_DIR&#125;/../libigl</span><br><span class="line">        $&#123;CMAKE_SOURCE_DIR&#125;/../../libigl</span><br><span class="line">        D:/Program\ Files/libigl</span><br><span class="line">        /usr</span><br><span class="line">        /usr/local</span><br><span class="line">        /usr/local/igl/libigl</span><br><span class="line">    PATH_SUFFIXES include</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;cmake中的windows 路径如果有空格，比如&lt;code&gt;D:/Program Files/libigl&lt;/code&gt;, 需要改成&lt;code&gt;D:/Program\ Files/libigl&lt;/code&gt;&lt;br&gt;&lt;figure class=&quot;highlight plai
      
    
    </summary>
    
      <category term="error" scheme="http://yoursite.com/categories/error/"/>
    
    
      <category term="cmake" scheme="http://yoursite.com/tags/cmake/"/>
    
  </entry>
  
  <entry>
    <title>hadoop集群搭建</title>
    <link href="http://yoursite.com/2018/09/26/hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2018/09/26/hadoop集群搭建/</id>
    <published>2018-09-26T04:09:45.000Z</published>
    <updated>2018-10-17T03:13:53.668Z</updated>
    
    <content type="html"><![CDATA[<h1 id="hadoop-集群搭建"><a href="#hadoop-集群搭建" class="headerlink" title="hadoop 集群搭建"></a>hadoop 集群搭建</h1><p>实验室当前hadoop集群节点如下：</p><table><thead><tr><th>主机名</th><th>用户名</th><th>IP</th><th>集群中的角色</th></tr></thead><tbody><tr><td>master</td><td>hadoop</td><td>10.13.61.122</td><td>NameNode、JobTracker</td></tr><tr><td>slave1</td><td>hadoop</td><td>10.13.61.125</td><td>DataNode、TaskTracker</td></tr><tr><td>slave2</td><td>hadoop</td><td>10.13.61.132</td><td>DataNode、TaskTracker</td></tr><tr><td>slave3</td><td>hadoop</td><td>10.13.61.146</td><td>DataNode、TaskTracker</td></tr><tr><td>slave4</td><td>hadoop</td><td>10.13.61.144</td><td>DataNode、TaskTracker</td></tr><tr><td>slave5</td><td>hadoop</td><td>10.13.61.143</td><td>DataNode、TaskTracker</td></tr><tr><td>slave6</td><td>hadoop</td><td>10.13.61.147</td><td>DataNode、TaskTracker</td></tr><tr><td>ajm-zju</td><td>hadoop</td><td>10.13.61.129</td><td>DataNode、TaskTracker</td></tr></tbody></table><p>各个节点的用户名均设置为 <strong>hadoop</strong>,密码均为 <strong>123456</strong>。其中slave3,slave4目前一般不使用。</p><p>hadoop集群安装主要有以下几个步骤：</p><ol><li>环境配置(host设置，ssh免密登录，Java安装等)</li><li>hadoop安装及修改配置文件</li><li>运行及测试</li></ol><a id="more"></a><h2 id="一、环境配置"><a href="#一、环境配置" class="headerlink" title="一、环境配置"></a>一、环境配置</h2><h3 id="1-用户、主机名、hosts文件"><a href="#1-用户、主机名、hosts文件" class="headerlink" title="1. 用户、主机名、hosts文件"></a>1. 用户、主机名、hosts文件</h3><p>由于目前已经搭建好的hadoop集群的用户名均为hadoop，所以需要在Ubuntu系统上新建一个hadoop用户，步骤如下：</p><h4 id="创建hadoop操作用户"><a href="#创建hadoop操作用户" class="headerlink" title="创建hadoop操作用户"></a>创建hadoop操作用户</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo useradd -m hadoop -s /bin/bash</span><br></pre></td></tr></table></figure><h4 id="给hadoop用户添加密码"><a href="#给hadoop用户添加密码" class="headerlink" title="给hadoop用户添加密码"></a>给hadoop用户添加密码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo passwd hadoop</span><br></pre></td></tr></table></figure><p>输入密码后回车，密码在输入时是不可见的。</p><h4 id="给hadoop用户分配sudo权限"><a href="#给hadoop用户分配sudo权限" class="headerlink" title="给hadoop用户分配sudo权限"></a>给hadoop用户分配sudo权限</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser hadoop sudo</span><br></pre></td></tr></table></figure><p>注销或重启系统，以hadoop用户登录</p><h4 id="切换用户"><a href="#切换用户" class="headerlink" title="切换用户"></a>切换用户</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su &lt;用户名&gt;，例如 su hadoop; su ajm</span><br></pre></td></tr></table></figure><p>输入要切换的用户密码，即可切换。</p><h4 id="安装vim、gedit"><a href="#安装vim、gedit" class="headerlink" title="安装vim、gedit"></a>安装vim、gedit</h4><p>vim是命令行编辑工具，gedit是图形界面编辑器，不习惯vim的话建议使用gedit<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install vim</span><br><span class="line">sudo apt-get install gedit</span><br></pre></td></tr></table></figure></p><h4 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h4><p><strong>不想修改主机名可以跳过此步，不会有影响</strong></p><p>在终端中输入hostname可以查看当前主机名，如下图：<br><img src="/images/1.jpg" alt=""><br>实际上在终端中有 <strong>hadoop@ajm-zju</strong>，其中hadoop是用户名，ajm-zju是主机名<br>比如要把新的主机加入集群，为了名称统一，可以将主机名改为 <strong>slave7</strong>,只需：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo hostname slave7 #暂时生效，重启后会失效</span><br><span class="line">sudo gedit /etc/hostname</span><br></pre></td></tr></table></figure></p><p>在文件中修改为slave7即可</p><h4 id="查看本机ip地址"><a href="#查看本机ip地址" class="headerlink" title="查看本机ip地址"></a>查看本机ip地址</h4><p>终端中输入以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig</span><br></pre></td></tr></table></figure></p><p><img src="/images/ip.jpg" alt=""><br>图中的 <strong>inet地址: 10.13.61.129</strong> 即为本机ip地址。</p><h4 id="配置hosts"><a href="#配置hosts" class="headerlink" title="配置hosts"></a>配置hosts</h4><p>/etc/hosts文件里维护了主机名和ip地址的映射关系，这样可以直接通过主机名通信，不用每次输入复杂的ip地址。通过cat命令可以直接在命令行中查看文件内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cat /etc/hosts</span><br></pre></td></tr></table></figure></p><p>在我的主机上，结果如下：<br><img src="/images/hosts.jpg" alt=""><br>可以hosts文件中保存了hadoop集群中其他主机的 <strong>ip地址<->主机名</-></strong> 映射关系，这样在hadoop进行通信时，可以直接通过主机名访问。所以如果集群加入新的主机，需要在新主机上修改hosts文件如上图，并加上本机地址映射<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/hosts</span><br></pre></td></tr></table></figure></p><p>终端中输入以上命令进行修改</p><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>如果配置成功，通过 <strong>ping</strong> 测试时，可以直接通过主机名而不需要ip地址<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ping master</span><br><span class="line">ping slave1</span><br><span class="line">ping 其他主机</span><br></pre></td></tr></table></figure></p><p>成功时结果如下：<br><img src="/images/ping.jpg" alt=""><br>注：ping指令会一直执行，可以通过 <code>ctrl+C</code> 停止</p><h3 id="2-配置SSH免密登录"><a href="#2-配置SSH免密登录" class="headerlink" title="2. 配置SSH免密登录"></a>2. 配置SSH免密登录</h3><p>由于hadoop集群中master主机需要调度各个slave，而这需要配置ssh远程登录服务。</p><h4 id="安装ssh"><a href="#安装ssh" class="headerlink" title="安装ssh"></a>安装ssh</h4><p>ubuntu 默认安装了ssh 客户端，没有安装服务端。运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -e|grep ssh</span><br></pre></td></tr></table></figure></p><p>结果应该与下文类似：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop@ajm-zju:/home/ajm$ ps -e|grep ssh</span><br><span class="line"> 1444 ?        00:00:00 sshd</span><br></pre></td></tr></table></figure></p><p>如果没有 <code>sshd</code> ，则说明没有安装ssh服务端，可以输入以下命令安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure></p><h4 id="ssh登录其他主机"><a href="#ssh登录其他主机" class="headerlink" title="ssh登录其他主机"></a>ssh登录其他主机</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh master</span><br></pre></td></tr></table></figure><p>出现身份警告时，输入yes并回车，需要输入密码时，请输入master主机的密码。<br>之后就登录了master主机，可以通过命令行操作maseter主机。<br><img src="/images/ssh.jpg" alt=""><br>注：退出登录使用<code>exit</code> 命令。</p><h4 id="生成RSA公私钥对"><a href="#生成RSA公私钥对" class="headerlink" title="生成RSA公私钥对"></a>生成RSA公私钥对</h4><p>但是每次ssh登录都需要输入密码太麻烦，所以可以通过公私钥的方式免密登录，配置方法是 <strong>A主机将公钥加入到B主机的authorized_keys中</strong>, 则A可以免密登录B。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa # 一路回车</span><br><span class="line">cd ~/.ssh # 公私钥对保存在此目录</span><br><span class="line">ls # 查看目录中的文件列表</span><br></pre></td></tr></table></figure></p><p>终端中输入以上命令后,可以看到有 id_rsa(私钥),id_rsa.pub(公钥)。<br>则将id_rsa.pub追加到master主机的authorized_keys中，则当前主机可以免密登录master主机。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub master</span><br></pre></td></tr></table></figure></p><p>如需要输入密码则输入master主机的密码</p><h4 id="ssh免密登录测试"><a href="#ssh免密登录测试" class="headerlink" title="ssh免密登录测试"></a>ssh免密登录测试</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh master</span><br></pre></td></tr></table></figure><p>如果直接登录成功，则配置正确。<br>登录master后，由于master主机已经生成了公私钥对，可以将master的公钥发给当前主机,实现master对当前主机的ssh免密登录。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub &lt;hostname&gt;</span><br></pre></td></tr></table></figure></p><p>如果出现错误，则需要在master主机中修改/etc/hosts，添加新主机的 ip<->hostname 映射。</-></p><h3 id="3-java安装"><a href="#3-java安装" class="headerlink" title="3. java安装"></a>3. java安装</h3><p>下载 <code>jdk-8u101.linux-x64.tar.gz</code>,运行以下命令解压到/usr目录下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /usr/java</span><br><span class="line">sudo tar -zxvf jdk-8u101.linux-x64.tar.gz -C /usr/java</span><br><span class="line">cd /usr/java/jdk1.8.0_101/bin</span><br><span class="line">./java -version #查看java版本</span><br></pre></td></tr></table></figure></p><p><img src="/images/java.jpg" alt=""><br>出现上图结果则正确安装</p><h4 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h4><p>在前面是通过<code>./java</code> 执行java可执行程序，但是为了执行这个程序，必须每次都切换到<code>/usr/java/jdk1.8.0_101/bin</code>目录下，为了能在任何目录下都能执行java的相关程序，需要配置环境变量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/profile</span><br></pre></td></tr></table></figure></p><p>在/etc/profile文件末尾添加如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_101</span><br><span class="line">export JRE_HOME=/usr/java/jdk1.8.0_101/jre</span><br><span class="line">export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JRE_HOME/lib</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></p><p>保存后退出。通过<code>source</code>命令使得上面的修改生效。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>输入以下命令测试是否成功配置环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></p><p><img src="/images/java1.jpg" alt=""><br>出现以上结果则成功配置。</p><h2 id="二、Hadoop安装"><a href="#二、Hadoop安装" class="headerlink" title="二、Hadoop安装"></a>二、Hadoop安装</h2><h3 id="1-安装及环境变量配置"><a href="#1-安装及环境变量配置" class="headerlink" title="1. 安装及环境变量配置"></a>1. 安装及环境变量配置</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>将hadoop-2.6.0.tar.gz解压到目录/opt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf hadoop-2.6.0.tar.gz -C /opt # 解压到/opt</span><br><span class="line">cd /opt      # 切到含有hadoop-2.6.0的目录下</span><br><span class="line">sudo chown -R hadoop:hadoop ./hadoop-2.6.0       # 修改文件权限</span><br></pre></td></tr></table></figure></p><h4 id="配置环境变量-1"><a href="#配置环境变量-1" class="headerlink" title="配置环境变量"></a>配置环境变量</h4><p>与java配置环境变量相同，在/etc/profile中追加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/opt/hadoop-2.6.0</span><br><span class="line">export HADOOP_LIB_NATIVE=$HADOOP_HOME/lib/native</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/lib</span><br></pre></td></tr></table></figure></p><p>保存后退出。通过<code>source</code>命令使得上面的修改生效。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>输入以下命令测试是否成功配置环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure></p><p><img src="/images/hadoop_v.jpg" alt=""><br>出现以上结果则成功配置。</p><h3 id="2-配置参数"><a href="#2-配置参数" class="headerlink" title="2. 配置参数"></a>2. 配置参数</h3><p>需要对所有的集群节点配置参数，其中大部分文件都是相同的，可以配置一个之后直接复制覆盖相关文件，而比如不同主机java安装路径不同的话，需要复制之后修改hadoop-env.sh和yarn-env.sh的相关参数。<br>hadoop需要配置一些参数才能成功运行，这些配置文件都在<code>/opt/hadoop-2.6.0/etc/hadoop/</code> 目录下。</p><h4 id="hadoop-env-sh-and-yarn-env-sh"><a href="#hadoop-env-sh-and-yarn-env-sh" class="headerlink" title="hadoop-env.sh and yarn-env.sh"></a>hadoop-env.sh and yarn-env.sh</h4><p>在<code>hadoop-env.sh</code>和<code>yarn-env.sh</code>中需要指定java安装目录。在文件末尾追加以下内容即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_101</span><br></pre></td></tr></table></figure></p><h4 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h4><p>slaves文件需要添加所有的slave节点主机名如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br><span class="line">slave4</span><br><span class="line">slave5</span><br><span class="line">slave6</span><br><span class="line">ajm-zju</span><br><span class="line">&lt;Your hostname&gt;</span><br></pre></td></tr></table></figure></p><h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><p>添加以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hdfs://master:8020&lt;/value&gt;</span><br><span class="line">      &lt;description&gt;&lt;/description&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;io.file.buffer.size&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;131072&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;/opt/hadoop-2.6.0/tmp&lt;/value&gt;</span><br><span class="line">      &lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><p>这个文件配置hdfs文件系统相关参数，添加以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;file:/opt/hadoop-2.6.0/dfs/name&lt;/value&gt;</span><br><span class="line">      &lt;description&gt;namenode上存储hdfs name空间元数据&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;file:/opt/hadoop-2.6.0/dfs/data&lt;/value&gt;</span><br><span class="line">      &lt;description&gt;datanode上数据块的物理存储位置&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;master:50090&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;true&lt;/value&gt;    </span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.permissions&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;false&lt;/value&gt;    </span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><h4 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h4><p>这个文件配置mapreduce任务相关参数。首先需要重命名mapred-site.xml.template文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv ./mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure></p><p>然后将以下内容添加到 mapred-site.xml:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;master:10020&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   </span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;master:19888&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.jobhistory.itermediate-done-dir&lt;/name&gt;  </span><br><span class="line">       &lt;value&gt;$&#123;hadoop.tmp.dir&#125;/mr-history/tmp&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;$&#123;hadoop.tmp.dir&#125;/mr-history/done&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"> </span><br><span class="line">   &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/user&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><h4 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h4><p>这个文件配置yarn资源管理调度的相关参数,添加以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;master:8032&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;master:8030&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;master:8035&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;master:8033&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt; </span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;master:8088&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;/user&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;20480&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;2048&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;2.1&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><h2 id="三、-运行及测试"><a href="#三、-运行及测试" class="headerlink" title="三、 运行及测试"></a>三、 运行及测试</h2><p>ssh登录master主机后，进行以下操作。</p><h3 id="格式化分布式文件系统"><a href="#格式化分布式文件系统" class="headerlink" title="格式化分布式文件系统"></a>格式化分布式文件系统</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format # 注意，首次搭建时需要此命令初始化，但添加新主机时不需要</span><br></pre></td></tr></table></figure><h3 id="运行文件系统管理器hdfs"><a href="#运行文件系统管理器hdfs" class="headerlink" title="运行文件系统管理器hdfs"></a>运行文件系统管理器hdfs</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure><h3 id="运行任务调度管理器yarn"><a href="#运行任务调度管理器yarn" class="headerlink" title="运行任务调度管理器yarn"></a>运行任务调度管理器yarn</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure><h3 id="查看相关进程"><a href="#查看相关进程" class="headerlink" title="查看相关进程"></a>查看相关进程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure><p>在master中可以看到：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@master ~]$ jps</span><br><span class="line">5859 SecondaryNameNode</span><br><span class="line">6003 ResourceManager</span><br><span class="line">6293 Jps</span><br><span class="line">24991 JobHistoryServer</span><br><span class="line">5695 NameNode</span><br></pre></td></tr></table></figure></p><p>在各个slave中可以看到：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop@ajm-zju:/$ jps</span><br><span class="line">28976 DataNode</span><br><span class="line">31952 NodeManager</span><br><span class="line">32158 Jps</span><br></pre></td></tr></table></figure></p><h3 id="Web查看信息"><a href="#Web查看信息" class="headerlink" title="Web查看信息"></a>Web查看信息</h3><p>在web上可以看到集群启动的信息：</p><ul><li>查看hdfs: <a href="master:50070" target="_blank" rel="noopener">master:50070</a></li><li>查看resourcemanager: <a href="master:8088" target="_blank" rel="noopener">master:8088</a></li></ul><p>如果web页面访问不了，可能是master主机的防火墙未关闭, ssh登录master主机,运行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status firewalld.service # 查看防火墙状态</span><br></pre></td></tr></table></figure></p><p><img src="/images/wall.jpg" alt=""><br>若图中的Active:显示为active，则需要关闭防火墙。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop firewalld.service # 关闭防火墙</span><br></pre></td></tr></table></figure></p><p>关闭后重新访问页面即可。</p><h3 id="关闭hadoop"><a href="#关闭hadoop" class="headerlink" title="关闭hadoop"></a>关闭hadoop</h3><p>执行相反的操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stop-yarn.sh</span><br><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure></p><blockquote><p>本文引用了以下内容</p><ul><li><a href="https://www.jianshu.com/p/4e0dc91ad86e" target="_blank" rel="noopener">Hadoop真分布式集群最速搭建攻略</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;hadoop-集群搭建&quot;&gt;&lt;a href=&quot;#hadoop-集群搭建&quot; class=&quot;headerlink&quot; title=&quot;hadoop 集群搭建&quot;&gt;&lt;/a&gt;hadoop 集群搭建&lt;/h1&gt;&lt;p&gt;实验室当前hadoop集群节点如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;用户名&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;集群中的角色&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;master&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.122&lt;/td&gt;
&lt;td&gt;NameNode、JobTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;slave1&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.125&lt;/td&gt;
&lt;td&gt;DataNode、TaskTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;slave2&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.132&lt;/td&gt;
&lt;td&gt;DataNode、TaskTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;slave3&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.146&lt;/td&gt;
&lt;td&gt;DataNode、TaskTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;slave4&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.144&lt;/td&gt;
&lt;td&gt;DataNode、TaskTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;slave5&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.143&lt;/td&gt;
&lt;td&gt;DataNode、TaskTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;slave6&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.147&lt;/td&gt;
&lt;td&gt;DataNode、TaskTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ajm-zju&lt;/td&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;10.13.61.129&lt;/td&gt;
&lt;td&gt;DataNode、TaskTracker&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;各个节点的用户名均设置为 &lt;strong&gt;hadoop&lt;/strong&gt;,密码均为 &lt;strong&gt;123456&lt;/strong&gt;。其中slave3,slave4目前一般不使用。&lt;/p&gt;
&lt;p&gt;hadoop集群安装主要有以下几个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;环境配置(host设置，ssh免密登录，Java安装等)&lt;/li&gt;
&lt;li&gt;hadoop安装及修改配置文件&lt;/li&gt;
&lt;li&gt;运行及测试&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
</feed>
