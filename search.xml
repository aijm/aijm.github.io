<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hadoop集群搭建]]></title>
    <url>%2F2018%2F09%2F26%2Fhadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[hadoop 集群搭建实验室当前hadoop集群节点如下： 主机名 用户名 IP 集群中的角色 master hadoop 10.13.61.122 NameNode、JobTracker slave1 hadoop 10.13.61.125 DataNode、TaskTracker slave2 hadoop 10.13.61.132 DataNode、TaskTracker slave3 hadoop 10.13.61.146 DataNode、TaskTracker slave4 hadoop 10.13.61.144 DataNode、TaskTracker slave5 hadoop 10.13.61.143 DataNode、TaskTracker slave6 hadoop 10.13.61.147 DataNode、TaskTracker ajm-zju hadoop 10.13.61.129 DataNode、TaskTracker 各个节点的用户名均设置为 hadoop,密码均为 123456。其中slave3,slave4目前一般不使用。 hadoop集群安装主要有以下几个步骤： 环境配置(host设置，ssh免密登录，Java安装等) hadoop安装及修改配置文件 运行及测试 一、环境配置1. 用户、主机名、hosts文件由于目前已经搭建好的hadoop集群的用户名均为hadoop，所以需要在Ubuntu系统上新建一个hadoop用户，步骤如下： 创建hadoop操作用户1sudo useradd -m hadoop -s /bin/bash 给hadoop用户添加密码1sudo passwd hadoop 输入密码后回车，密码在输入时是不可见的。 给hadoop用户分配sudo权限1sudo adduser hadoop sudo 注销或重启系统，以hadoop用户登录 切换用户1su &lt;用户名&gt;，例如 su hadoop; su ajm 输入要切换的用户密码，即可切换。 安装vim、geditvim是命令行编辑工具，gedit是图形界面编辑器，不习惯vim的话建议使用gedit12sudo apt-get install vimsudo apt-get install gedit 修改主机名不想修改主机名可以跳过此步，不会有影响 在终端中输入hostname可以查看当前主机名，如下图：实际上在终端中有 hadoop@ajm-zju，其中hadoop是用户名，ajm-zju是主机名比如要把新的主机加入集群，为了名称统一，可以将主机名改为 slave7,只需：12sudo hostname slave7 #暂时生效，重启后会失效sudo gedit /etc/hostname 在文件中修改为slave7即可 查看本机ip地址终端中输入以下命令：1ifconfig 图中的 inet地址: 10.13.61.129 即为本机ip地址。 配置hosts/etc/hosts文件里维护了主机名和ip地址的映射关系，这样可以直接通过主机名通信，不用每次输入复杂的ip地址。通过cat命令可以直接在命令行中查看文件内容：1sudo cat /etc/hosts 在我的主机上，结果如下：可以hosts文件中保存了hadoop集群中其他主机的 ip地址主机名 映射关系，这样在hadoop进行通信时，可以直接通过主机名访问。所以如果集群加入新的主机，需要在新主机上修改hosts文件如上图，并加上本机地址映射1sudo gedit /etc/hosts 终端中输入以上命令进行修改 测试如果配置成功，通过 ping 测试时，可以直接通过主机名而不需要ip地址123ping masterping slave1ping 其他主机 成功时结果如下：注：ping指令会一直执行，可以通过 ctrl+C 停止 2. 配置SSH免密登录由于hadoop集群中master主机需要调度各个slave，而这需要配置ssh远程登录服务。 安装ssh如果终端中输入 ssh显示找不到命令，可以输入以下命令安装：1sudo apt-get install openssh-server ssh登录其他主机1ssh master 出现身份警告时，输入yes并回车，需要输入密码时，请输入master主机的密码。之后就登录了master主机，可以通过命令行操作maseter主机。注：退出登录使用exit 命令。 生成RSA公私钥对但是每次ssh登录都需要输入密码太麻烦，所以可以通过公私钥的方式免密登录，配置方法是 A主机将公钥加入到B主机的authorized_keys中, 则A可以免密登录B。123ssh-keygen -t rsa # 一路回车cd ~/.ssh # 公私钥对保存在此目录ls # 查看目录中的文件列表 终端中输入以上命令后,可以看到有 id_rsa(私钥),id_rsa.pub(公钥)。则将id_rsa.pub追加到master主机的authorized_keys中，则当前主机可以免密登录master主机。1ssh-copy-id -i ~/.ssh/id_rsa.pub master 如需要输入密码则输入master主机的密码 ssh免密登录测试1ssh master 如果直接登录成功，则配置正确。登录master后，由于master主机已经生成了公私钥对，可以将master的公钥发给当前主机,实现master对当前主机的ssh免密登录。1ssh-copy-id -i ~/.ssh/id_rsa.pub &lt;hostname&gt; 如果出现错误，则需要在master主机中修改/etc/hosts，添加新主机的 iphostname 映射。 3. java安装下载 jdk-8u101.linux-x64.tar.gz,运行以下命令解压到/usr目录下:1234sudo mkdir /usr/javasudo tar -zxvf jdk-8u101.linux-x64.tar.gz -C /usr/javacd /usr/java/jdk1.8.0_101/bin./java -version #查看java版本 出现上图结果则正确安装 配置环境变量在前面是通过./java 执行java可执行程序，但是为了执行这个程序，必须每次都切换到/usr/java/jdk1.8.0_101/bin目录下，为了能在任何目录下都能执行java的相关程序，需要配置环境变量。1sudo gedit /etc/profile 在/etc/profile文件末尾添加如下1234export JAVA_HOME=/usr/java/jdk1.8.0_101export JRE_HOME=/usr/java/jdk1.8.0_101/jreexport CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JRE_HOME/libexport PATH=$PATH:$JAVA_HOME/bin 保存后退出。通过source命令使得上面的修改生效。1sudo source /etc/profile 输入以下命令测试是否成功配置环境变量1java -version 出现以上结果则成功配置。 二、Hadoop安装1. 安装及环境变量配置安装将hadoop-2.6.0.tar.gz解压到目录/opt1sudo tar -zxvf hadoop-2.6.0.tar.gz -C /opt 配置环境变量与java配置环境变量相同，在/etc/profile中追加：12345export HADOOP_HOME=/opt/hadoop-2.6.0export HADOOP_LIB_NATIVE=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbinexport PATH=$PATH:$HADOOP_HOME/lib 保存后退出。通过source命令使得上面的修改生效。1sudo source /etc/profile 输入以下命令测试是否成功配置环境变量1hadoop version 出现以上结果则成功配置。 2. 配置参数需要对所有的集群节点配置参数，其中大部分文件都是相同的，可以配置一个之后直接复制覆盖相关文件，而比如不同主机java安装路径不同的话，需要复制之后修改hadoop-env.sh和yarn-env.sh的相关参数。hadoop需要配置一些参数才能成功运行，这些配置文件都在/opt/hadoop-2.6.0/etc/hadoop/ 目录下。 hadoop-env.sh and yarn-env.sh在hadoop-env.sh和yarn-env.sh中需要指定java安装目录。在文件末尾追加以下内容即可：1export JAVA_HOME=/usr/java/jdk1.8.0_101 slavesslaves文件需要添加所有的slave节点主机名如下：12345678slave1slave2slave3slave4slave5slave6ajm-zju&lt;Your hostname&gt; core-site.xml添加以下内容：12345678910111213141516&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:8020&lt;/value&gt; &lt;description&gt;&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop-2.6.0/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml这个文件配置hdfs文件系统相关参数，添加以下内容：1234567891011121314151617181920212223242526272829&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/opt/hadoop-2.6.0/dfs/name&lt;/value&gt; &lt;description&gt;namenode上存储hdfs name空间元数据&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/opt/hadoop-2.6.0/dfs/data&lt;/value&gt; &lt;description&gt;datanode上数据块的物理存储位置&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml这个文件配置mapreduce任务相关参数。首先需要重命名mapred-site.xml.template文件：1mv ./mapred-site.xml.template mapred-site.xml 然后将以下内容添加到 mapred-site.xml:12345678910111213141516171819202122232425262728293031&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.itermediate-done-dir&lt;/name&gt; &lt;value&gt;$&#123;hadoop.tmp.dir&#125;/mr-history/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt; &lt;value&gt;$&#123;hadoop.tmp.dir&#125;/mr-history/done&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobtracker.staging.root.dir&lt;/name&gt; &lt;value&gt;/user&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml这个文件配置yarn资源管理调度的相关参数,添加以下内容：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8035&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;master:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt; &lt;value&gt;/user&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;20480&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;2.1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 三、 运行及测试ssh登录master主机后，进行以下操作。 格式化分布式文件系统1hdfs namenode -format # 注意，首次搭建时需要此命令初始化，但添加新主机时不需要 运行文件系统管理器hdfs1start-dfs.sh 运行任务调度管理器yarn1start-yarn.sh 查看相关进程1jps 在master中可以看到：123456[hadoop@master ~]$ jps5859 SecondaryNameNode6003 ResourceManager6293 Jps24991 JobHistoryServer5695 NameNode 在各个slave中可以看到：1234hadoop@ajm-zju:/$ jps28976 DataNode31952 NodeManager32158 Jps Web查看信息在web上可以看到集群启动的信息： 查看hdfs: master:50070 查看resourcemanager: master:8088 如果web页面访问不了，可能是master主机的防火墙未关闭, ssh登录master主机,运行以下命令：1sudo systemctl status firewalld.service # 查看防火墙状态 若图中的Active:显示为active，则需要关闭防火墙。1sudo systemctl stop firewalld.service # 关闭防火墙 关闭后重新访问页面即可。 关闭hadoop执行相反的操作12stop-yarn.shstop-dfs.sh 本文引用了以下内容 Hadoop真分布式集群最速搭建攻略]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
</search>
